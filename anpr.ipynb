{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# get working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "# go to cd desktop\n",
    "os.chdir('/Users/kirtisikka/Desktop/newyolo/yolov7')\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov7.git\n",
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "!python3 train.py --device \"cpu\" --batch-size 2 --epochs 20  --data \"License-Plate-Recognition-4/data.yaml\" --name numberplatedetect --weights yolov7-tiny.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python3 train.py --device \"cpu\" --weights yolov7-tiny.pt  --epochs 20 --batch-size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "# get current directory\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weigths = torch.load('Best model.pt')\n",
    "model = weigths['model']\n",
    "model = model.half().to(device)\n",
    "_ = model.eval()\n",
    "\n",
    "img_path = 'yolov7/License-Plate-Recognition-4/test/images/00c82d64185293a7_jpg.rf.d927fad96de9f7b21d10616035d07517.jpg'\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Get the frame width and height.\n",
    "h,w,c = img.shape\n",
    "frame_width = w\n",
    "frame_height = h\n",
    "\n",
    "\n",
    "orig_image = img\n",
    "image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "image = letterbox(image, (frame_width), stride=64, auto=True)[0]\n",
    "image_ = image.copy()\n",
    "image = transforms.ToTensor()(image)\n",
    "image = torch.tensor(np.array([image.numpy()]))\n",
    "image = image.to(device)\n",
    "image = image.half()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, _ = model(image)\n",
    "\n",
    "output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], kpt_label=True)\n",
    "output = output_to_keypoint(output)\n",
    "nimg = image[0].permute(1, 2, 0) * 255\n",
    "nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "for idx in range(output.shape[0]):\n",
    "    # plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "\n",
    "    # Comment/Uncomment the following lines to show bounding boxes around persons.\n",
    "    xmin, ymin = (output[idx, 2]-output[idx, 4]/2), (output[idx, 3]-output[idx, 5]/2)\n",
    "    xmax, ymax = (output[idx, 2]+output[idx, 4]/2), (output[idx, 3]+output[idx, 5]/2)\n",
    "\n",
    "    plate_roi = nimg[int(ymin):int(ymax),int(xmin):int(xmax)]\n",
    "    cv2.imshow('Plate',plate_roi)\n",
    "\n",
    "    cv2.putText(nimg, \"Number Plate\", (int(xmin), int(ymin)-5), cv2.FONT_HERSHEY_SIMPLEX,1, (228, 79, 215), 2)\n",
    "    cv2.rectangle(\n",
    "        nimg,\n",
    "        (int(xmin), int(ymin)),\n",
    "        (int(xmax), int(ymax)),\n",
    "        color=(228, 79, 215),\n",
    "        thickness=1,\n",
    "        lineType=cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "# Convert from BGR to RGB color format.\n",
    "cv2.imwrite('result.jpg',nimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torchvision import transforms\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weigths = torch.load('Best model.pt')\n",
    "model = weigths['model']\n",
    "model = model.half().to(device)\n",
    "_ = model.eval()\n",
    "\n",
    "video_path = 'small.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if (cap.isOpened() == False):\n",
    "  print('Error while trying to read video. Please check path again')\n",
    "\n",
    "# Get the frame width and height.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Pass the first frame through `letterbox` function to get the resized image,\n",
    "# to be used for `VideoWriter` dimensions. Resize by larger side.\n",
    "vid_write_image = letterbox(cap.read()[1], (frame_width), stride=64, auto=True)[0]\n",
    "resize_height, resize_width = vid_write_image.shape[:2]\n",
    "\n",
    "# Define codec and create VideoWriter object .\n",
    "out = cv2.VideoWriter(\"result.mp4\",\n",
    "                    cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
    "                    (resize_width, resize_height))\n",
    "\n",
    "\n",
    "frame_count = 0 # To count total frames.\n",
    "total_fps = 0 # To get the final frames per second.\n",
    "\n",
    "\n",
    "while(cap.isOpened):\n",
    "  # Capture each frame of the video.\n",
    "  ret, frame = cap.read()\n",
    "  if ret:\n",
    "      orig_image = frame\n",
    "      image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "      image = letterbox(image, (frame_width), stride=64, auto=True)[0]\n",
    "      image_ = image.copy()\n",
    "      image = transforms.ToTensor()(image)\n",
    "      image = torch.tensor(np.array([image.numpy()]))\n",
    "      image = image.to(device)\n",
    "      image = image.half()\n",
    "\n",
    "      # Get the start time.\n",
    "      start_time = time.time()\n",
    "      with torch.no_grad():\n",
    "          output, _ = model(image)\n",
    "        # Get the end time.\n",
    "      end_time = time.time()\n",
    "     \n",
    "      fps = 1 / (end_time - start_time)\n",
    "      # Add fps to total fps.\n",
    "      total_fps += fps\n",
    "      # Increment frame count.\n",
    "      frame_count += 1\n",
    "\n",
    "      output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], kpt_label=True)\n",
    "      output = output_to_keypoint(output)\n",
    "      nimg = image[0].permute(1, 2, 0) * 255\n",
    "      nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "      nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "      for idx in range(output.shape[0]):\n",
    "          # plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "\n",
    "          # Comment/Uncomment the following lines to show bounding boxes around persons.\n",
    "          xmin, ymin = (output[idx, 2]-output[idx, 4]/2), (output[idx, 3]-output[idx, 5]/2)\n",
    "          xmax, ymax = (output[idx, 2]+output[idx, 4]/2), (output[idx, 3]+output[idx, 5]/2)\n",
    "\n",
    "          plate_roi = nimg[int(ymin):int(ymax),int(xmin):int(xmax)]\n",
    "          cv2.imshow('Plate',plate_roi)\n",
    "     \n",
    "          cv2.putText(nimg, \"Number Plate\", (int(xmin), int(ymin)-5), cv2.FONT_HERSHEY_SIMPLEX,1, (228, 79, 215), 2)\n",
    "          cv2.rectangle(\n",
    "              nimg,\n",
    "              (int(xmin), int(ymin)),\n",
    "              (int(xmax), int(ymax)),\n",
    "              color=(228, 79, 215),\n",
    "              thickness=1,\n",
    "              lineType=cv2.LINE_AA\n",
    "          )\n",
    "\n",
    "      # Write the FPS on the current frame.\n",
    "      cv2.putText(nimg, f\"{fps:.3f} FPS\", (15, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                  1, (0, 255, 0), 2)\n",
    "      # Convert from BGR to RGB color format.\n",
    "      cv2.imshow('image', nimg)\n",
    "      out.write(nimg)\n",
    "      print(f\"{fps:.3f} FPS\")\n",
    "      # Press `q` to exit.\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break\n",
    "  else:\n",
    "      break\n",
    "# Release VideoCapture().\n",
    "cap.release()\n",
    "# Close all frames and video windows.\n",
    "cv2.destroyAllWindows()\n",
    "# Calculate and print the average FPS.\n",
    "avg_fps = total_fps / frame_count\n",
    "print(f\"Average FPS: {avg_fps:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
